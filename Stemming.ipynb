{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our task for any ML project is to reduce the insignificant data as much as possible. Because more data means more time to train. Suppose your exam has huge syllabus. So you'll need more time to train/study. Same things goes for ML. so we've removed punctuations and stop words\n",
    "\n",
    "# Another data cleaning technique is: `stemming`\n",
    "\n",
    "### in a tree, there is stem and also branches connected to the stem. Similarly in any language, the root word is called stem and the words producing from the stem, you can call it branch word of the stem. Say we'be a word: change. the words connected to them can be: changes, changing, changed. So if we can convert all of them in the stem word, we can reduce lots of data. Both stemming and lemmatization technique do the same. It's your choice which one will you use for your project\n",
    "\n",
    "## The difference between `stemming and lemmatization` is that they use different algorithms to produce the stem word. Stemming cuts of the prefixes/suffixes and produce a word that sometimes don't have any meaning. But lemmatization technique always produce a word that has dictionary meaning\n",
    "\n",
    "## You may think if `lemmatization` produce dictionary word and `stemming` produce non-dictionary word, why do we use stemming\n",
    "\n",
    "# here's the catch, `stemming` just cuts of the prefix/suffix which takes less time and `lemmatization` search the whole dictionary before producing the dictionary word which takes lots of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['root', 'roots', 'rooted', 'rooting']\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"root\", \"roots\", \"rooted\", \"rooting\"]\n",
    "\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "root\n",
      "root\n",
      "root\n"
     ]
    }
   ],
   "source": [
    "for stemmed in word_list:\n",
    "    print(ps.stem(stemmed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
